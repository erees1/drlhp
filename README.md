# Deep reinforcement learning from human preferences

Status: **In progress**

Replication of [Deep reinforcement learning from human preferences](https://arxiv.org/abs/1706.03741) by Christiano et al. (2017).

TODO:
- [x] Implement PPO
- [x] Test on toy environments
- [ ] Create human feedback loop and reward model training
- [ ] Validate by training https://github.com/mrahtz/gym-moving-dot on human feedback
- [ ] Recreate backflip example from the paper
